{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:/capestone_project/2-Data/sample30.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senti-analysis\n",
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reviews_title = data.reviews_title.str.lower()\n",
    "data.reviews_text = data.reviews_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 stands for positive and 0 is for negative\n",
    "data['user_senti_encode'] = np.where(data[\"user_sentiment\"].str.contains(\"Positive\"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEt me see dropping these entries to see if the accuracy increases\n",
    "data = data[(data['reviews_rating']>=2) | (data['user_senti_encode'] != 1)]\n",
    "#this drastically improves the score. Not kidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reviews_text.value_counts()[:10] # To see how to clean the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'this review was collected as part of a promotion.'\n",
    "data['reviews_text'] = data.reviews_text.apply(lambda sentence:re.sub(pattern,'',sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reviews_title.fillna(value= 'nan',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing the whitespaces\n",
    "data['reviews_title']=data.reviews_title.apply(lambda sentence: re.sub(' +', ' ',sentence.strip()))\n",
    "\n",
    "data['reviews_text'] = data.reviews_text.apply(lambda sentence: re.sub(' +', ' ',sentence.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good flavor.'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reviews_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.drop_duplicates(subset=['word_count','reviews_text'],keep = 'first',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reviews_text.isnull().sum()\n",
    "data.reviews_title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5527     i found this at a price that could not be pass...\n",
       "15069    i created a two binder dossier for my husband'...\n",
       "21855    cookie reviews jayne in our class this week we...\n",
       "23159    i can't decide if i like this movie or not. i ...\n",
       "28886    i received this conditioner as part of an infl...\n",
       "Name: reviews_text, dtype: object"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.reviews_text.str.contains('promotion')].reviews_text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i received this conditioner as part of an influenster promotion (for free) and boy am i glad i did! this conditioner does a pretty good job with my thick, wavy hair. i will be interested to see how it treats my hair over time. definitely try this for those of you who have thick, oily hair! although i received this as a promotion, the opinions are my own.'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.reviews_text.str.contains('promotion')].reviews_text[28886]\n",
    "# The keyword promotion has no more magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding other such keywords that can caues the similar issue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28920    i received this product from influenster for t...\n",
       "28926    i received this product free from influenster ...\n",
       "28949    i have been using this conditioner with the co...\n",
       "28953    i received a free sample of this product for r...\n",
       "28978    i am not in love with the conditioner. the cla...\n",
       "29003    i received this product from influenster for t...\n",
       "29009    i received this product free from influenster ...\n",
       "29042    i received a free sample of this product for r...\n",
       "29054    i am not in love with the conditioner. the cla...\n",
       "29067    loreal extraordinary clay pre-shampoo mask (sp...\n",
       "29123    the mask leaves my hair feeling too dry but th...\n",
       "29289    i was quite impressed in this conditioner. my ...\n",
       "29336    i received this product complimentary for revi...\n",
       "29473    the mask leaves my hair feeling too dry but th...\n",
       "29493    i received this product complimentary for revi...\n",
       "29522    loreal extraordinary clay pre-shampoo mask (sp...\n",
       "29557    i was quite impressed in this conditioner. my ...\n",
       "29850    i have been using this product for the last we...\n",
       "29863    to be honest i love l'oral products but never ...\n",
       "29945    i love conditioners! and this is soooo good! i...\n",
       "29996    i love it , i received this for review purpose...\n",
       "Name: reviews_text, dtype: object"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.reviews_text.str.contains('review purpose')].reviews_text[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i am absolutely in love with this aussie aussome shampoo. i have been using it for a little over a week and my hair is visibly shinier, and smooth to the point where i can run my fingers through it and there isn't a single tangle.this leaves my hair feeling really clean, but also really smooth and shiny. this is also a pretty good deal. i recommend using it with the aussome conditioner. i received this product for free to review from influenster for testing purposes.\""
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.reviews_text.str.contains('influenster')].reviews_text[1099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_count'] = data.reviews_text.apply(lambda sentence: True if len(sentence)>=25 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['word_count','reviews_text'],keep = 'first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good flavor.'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reviews_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['tittex'] = data.reviews_title+'. '+data.reviews_text # This reduced the accuracy; revoked to just the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data that is to be used for sentiment analysis\n",
    "nlp_data = data.loc[:,['reviews_text','user_senti_encode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x218ce82c908>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='user_senti_encode', data=nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are any missing entries, then we can remove that row\n",
    "#nlp_data.text.fillna(value='are',inplace=True)\n",
    "nlp_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the not from the list as its always usefull\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('don')\n",
    "stop_words.append('influenster')\n",
    "stop_words.append('promotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleans a sentence that is passed, notice that stemming/lammetization is yet to be done\n",
    "def nlp_preprocesser(sentence):\n",
    "    #print(sentence)\n",
    "    #sentence = re.sub(' +', ' ',sentence.strip()) # Removes the white spaces\n",
    "    words = word_tokenize(sentence)\n",
    "    #Remove punctuation \n",
    "    words=[word for word in words if word.isalpha()]\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    # Removing the proper nouns from the text\n",
    "    words = nltk.pos_tag(words)\n",
    "    words = [text for (text,pos) in words if pos != 'NNP']# Proper noun\n",
    "   \n",
    "    words = \" \".join(words)# Join to save space\n",
    "    return words # Returns clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st stage of preprocessed text\n",
    "nlp_data['preprocessed_text']=pd.Series(nlp_data.reviews_text).apply(nlp_preprocesser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sent_lemmatizer(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    n_of_words = 150 # Restrics the number of words to 10\n",
    "    words = word_tokenize(sentence)\n",
    "    words = nltk.pos_tag(words)\n",
    "    # Convert the nltk taggs to wordnet tags\n",
    "    words = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), words)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in words:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "   # Restricts the number of words to n_of_words \n",
    "    if len(lemmatized_sentence) >= n_of_words:\n",
    "        lemmatized_sentence = random.sample(lemmatized_sentence,n_of_words)\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data['lemmatized_text'] = pd.Series(nlp_data.preprocessed_text).apply(sent_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limiting the text length.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'condition healthy receive product complimentary really saved hair product really give extra boost health strength bring hair back life help hair many way'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data['lemmatized_text'][29999    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf vectoriser|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import imblearn\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(nlp_data.lemmatized_text,nlp_data.user_senti_encode,test_size = 0.2,random_state =17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectoriser = TfidfVectorizer(ngram_range = (1,2),\n",
    "                                    strip_accents='unicode',\n",
    "                                    min_df = 20, max_df = 0.5,\n",
    "                                   sublinear_tf=True) # an bigram would have \"not ___\" this would really improve the accuracy\n",
    "# a word whe  considered should have atleast shown up in 5 of the documents in order to be vectorised. And should nt be there in more than 50% of the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector = tf_idf_vectoriser.fit_transform(X_train)#.toarray().astype(np.uint8) # fit transform train, so that we can fix the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfIdf\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "filename = f'to_submit/tf_idf_{date}.sav'\n",
    "pickle.dump(tf_idf_vectoriser, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vector = tf_idf_vectoriser.transform(X_test)#.toarray().astype(np.uint8) # Transforming the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE used to fix the class imbalance in the training\n",
    "class_imb = imblearn.over_sampling.SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector_imb, y_train_imb = class_imb.fit_resample(X_train_vector,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vector_imb, y_test_imb = class_imb.fit_resample(X_test_vector,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18865\n",
       "0    18865\n",
       "Name: user_senti_encode, dtype: int64"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if imbalance is sorted\n",
    "y_train_imb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test\n",
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score # to evaluvate the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate log regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_vector_imb,y_train_imb) # Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(LOG_REG): 0.9334216803604559\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94     19819\n",
      "           1       0.91      0.96      0.93     17911\n",
      "\n",
      "    accuracy                           0.93     37730\n",
      "   macro avg       0.93      0.93      0.93     37730\n",
      "weighted avg       0.93      0.93      0.93     37730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on train\n",
    "y_pred_train = log_reg.predict(X_train_vector_imb)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy(LOG_REG):\", accuracy_score(y_pred_train, y_train_imb))\n",
    "print(classification_report(y_pred_train, y_train_imb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy(LOG_REG): 0.8351706593173628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      4126\n",
      "           1       0.90      0.80      0.84      5308\n",
      "\n",
      "    accuracy                           0.84      9434\n",
      "   macro avg       0.84      0.84      0.83      9434\n",
      "weighted avg       0.84      0.84      0.84      9434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on test\n",
    "y_pred_test = log_reg.predict(X_test_vector_imb)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy(LOG_REG):\", accuracy_score(y_pred_test, y_test_imb))\n",
    "print(classification_report(y_pred_test, y_test_imb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9335406235190989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_test = log_reg.predict(X_test_vector_imb)\n",
    "print( roc_auc_score(y_pred_test, y_test_imb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vector_imb.toarray(),y_train_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'NB_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy(LOG_REG): 0.8523018997090536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.43      0.55      1229\n",
      "           1       0.86      0.96      0.91      4614\n",
      "\n",
      "    accuracy                           0.85      5843\n",
      "   macro avg       0.81      0.70      0.73      5843\n",
      "weighted avg       0.84      0.85      0.84      5843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on test\n",
    "y_pred_test = model.predict(X_test_vector.toarray())\n",
    "\n",
    "\n",
    "print(\"Test Accuracy(LOG_REG):\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(LOG_REG): 0.8769137889398696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     20704\n",
      "           1       0.88      0.88      0.88     20706\n",
      "\n",
      "    accuracy                           0.88     41410\n",
      "   macro avg       0.88      0.88      0.88     41410\n",
      "weighted avg       0.88      0.88      0.88     41410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on train\n",
    "y_pred_train = model.predict(X_train_vector_imb.toarray())\n",
    "\n",
    "\n",
    "print(\"Train Accuracy(LOG_REG):\", accuracy_score(y_pred_train, y_train_imb))\n",
    "print(classification_report(y_pred_train, y_train_imb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[40,50,60],\n",
    "         'min_samples_leaf': [3,5],\n",
    "         'max_features': [50,60],\n",
    "         'n_estimators': [200,300,400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = model_rf, param_grid = params, cv = 4, n_jobs = -1, verbose = 1, scoring = 'accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Wall time: 1h 14min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=17),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [40, 50, 60], 'max_features': [50, 60],\n",
       "                         'min_samples_leaf': [3, 5],\n",
       "                         'n_estimators': [200, 300, 400]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train_vector_imb,y_train_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=60, max_features=60, min_samples_leaf=3,\n",
       "                       n_estimators=300, n_jobs=-1, random_state=17)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy(LOG_REG): 0.9156255348279994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.66       765\n",
      "           1       0.95      0.96      0.95      5078\n",
      "\n",
      "    accuracy                           0.92      5843\n",
      "   macro avg       0.82      0.80      0.81      5843\n",
      "weighted avg       0.91      0.92      0.91      5843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on test\n",
    "y_pred_test = rf_best.predict(X_test_vector)\n",
    "\n",
    "\n",
    "print(\"Test Accuracy(LOG_REG):\", accuracy_score(y_pred_test, y_test))\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(LOG_REG): 0.9702004346776141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97     21121\n",
      "           1       0.96      0.98      0.97     20289\n",
      "\n",
      "    accuracy                           0.97     41410\n",
      "   macro avg       0.97      0.97      0.97     41410\n",
      "weighted avg       0.97      0.97      0.97     41410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluvation of the model on train\n",
    "y_pred_train = rf_best.predict(X_train_vector_imb)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy(LOG_REG):\", accuracy_score(y_pred_train, y_train_imb))\n",
    "print(classification_report(y_pred_train, y_train_imb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename_2022_02_16-11_13_19_PM\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saver\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "filename = f'to_submit/log_reg_{date}.sav'\n",
    "pickle.dump(log_reg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saver\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "filename = f'to_submit/naive_{date}.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saver\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "filename = f'to_submit/random_forest_{date}.sav'\n",
    "pickle.dump(rf_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_vec = tf_idf_vectoriser.transform(pd.Series('love'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19097    love would recommend product anytime need litt...\n",
       "5227     great buy pack love movie sequel ca wait next ...\n",
       "3181                          movie entertain really funny\n",
       "615       try olay product level accord age skin care need\n",
       "15833    like product natural feel nice lip especially ...\n",
       "                               ...                        \n",
       "13651    love disinfect wipe use everything feel confid...\n",
       "18214    pretty good product careful replace glass frag...\n",
       "1377     poor think might bad batch product lose viscos...\n",
       "9615     love fresh smell wipe well way clean great job...\n",
       "27965                           movie great kid adult cute\n",
       "Name: lemmatized_text, Length: 5843, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hi\n",
       "dtype: object"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(ho_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
